# -*- coding: utf-8 -*-
"""Healthy vs Rotten Fruits and Vegetables .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EkndapBzUHLwnlAgE6UQzgsfGb95g4_0
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten

!unzip fruit-and-vegetable-disease-healthy-vs-rotten.zip -d dataset

import os

import shutil

from tensorflow.keras.preprocessing.image import ImageDataGenerator

from sklearn.model_selection import train_test_split

import shutil

from sklearn.model_selection import train_test_split

from tensorflow.keras.applications.vgg16 import VGG16

from tensorflow.keras.layers import Dense, Flatten

from tensorflow.keras.models import Model

from keras.callbacks import EarlyStopping

from keras.optimizers import Adam

from tensorflow.keras.applications.resnet50 import ResNet50

from tensorflow.keras.layers import Dense, Flatten

from tensorflow.keras.models import Model

from keras.preprocessing import image

from keras.applications.vgg16 import preprocess_input

from tensorflow.keras.preprocessing.image import load_img, img_to_array

import random

from IPython.display import Image, display

dataset_dir = 'dataset/Fruit And Vegetable Diseases Dataset'
classes=os.listdir(dataset_dir)

import os

print(os.listdir("dataset"))
print(os.listdir("dataset/Fruit And Vegetable Diseases Dataset"))
print(classes)#Both classes and 2nd print statement are same

output_dir = 'output_dataset'
os.makedirs(output_dir, exist_ok=True)
os.makedirs(os.path.join(output_dir, 'train'), exist_ok=True)
os.makedirs(os.path.join(output_dir, 'val'), exist_ok=True)
os.makedirs(os.path.join(output_dir, 'test'), exist_ok=True)

for cls in classes:
    os.makedirs(os.path.join(output_dir, 'train', cls), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'val', cls), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'test', cls), exist_ok=True)

    class_dir = os.path.join(dataset_dir, cls)
    images = os.listdir(class_dir)[:200]

    train_and_val_images, test_images = train_test_split(images, test_size=0.2, random_state=42)
    train_images, val_images = train_test_split(train_and_val_images, test_size=0.25, random_state=42)


    for img in train_images:
        shutil.copy(os.path.join(class_dir, img), os.path.join(output_dir, 'train', cls, img))

    for img in val_images:
        shutil.copy(os.path.join(class_dir, img), os.path.join(output_dir, 'val', cls, img))

    for img in test_images:
        shutil.copy(os.path.join(class_dir, img), os.path.join(output_dir, 'test', cls, img))

print("Dataset split into training, validation, and test sets.")

dataset_dir = '/content/output_dataset'
train_dir = os.path.join(dataset_dir, 'train')
val_dir = os.path.join(dataset_dir, 'val')
test_dir = os.path.join(dataset_dir, 'test')

IMG_SIZE = (224, 224)

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='binary'
)

val_generator = val_test_datagen.flow_from_directory(
    val_dir,
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='binary'
)

test_generator = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=IMG_SIZE,
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

print(train_generator.class_indices)
print(val_generator.class_indices)
print(test_generator.class_indices)

folder_path = '/content/output_dataset/train/Banana__Healthy'

#List all files in the folder

image_files = [f for f in os.listdir (folder_path) if f.endswith(('.jpg','.png','.jpeg'))]

# Select a random image from the list

selected_image = random.choice(image_files)

# Display the randomly selected image

image_path = os.path.join(folder_path, selected_image)

display(Image(filename=image_path))

folder_path = '/content/output_dataset/test/Jujube__Healthy'


#List all files in the folder

image_files = [f for f in os.listdir (folder_path) if f.endswith(('.jpg','.png','.jpeg'))]

# Select a random image from the list

selected_image = random.choice(image_files)

# Display the randomly selected image

image_path = os.path.join(folder_path, selected_image)

display(Image(filename=image_path))

folder_path = '/content/output_dataset/test/Pomegranate__Healthy'

#List all files in the folder

image_files = [f for f in os.listdir (folder_path) if f.endswith(('.jpg','.png','.jpeg'))]

# Select a random image from the list

selected_image = random.choice(image_files)

# Display the randomly selected image

image_path = os.path.join(folder_path, selected_image)

display(Image(filename=image_path))

folder_path = '/content/output_dataset/test/Cucumber__Rotten'


#List all files in the folder

image_files = [f for f in os.listdir (folder_path) if f.endswith(('.jpg','.png','.jpeg'))]

# Select a random image from the list

selected_image = random.choice(image_files)

# Display the randomly selected image

image_path = os.path.join(folder_path, selected_image)

display(Image(filename=image_path))

trainpath = "/content/output_dataset/train"

testpath="/content/output_dataset/test"

train_datagen = ImageDataGenerator(rescale = 1./255,zoom_range= 0.2, shear_range= 0.2)

test_datagen = ImageDataGenerator (rescale = 1./255)

train = train_datagen.flow_from_directory (trainpath, target_size = (224,224), batch_size = 20)

test = test_datagen.flow_from_directory(testpath, target_size = (224,224), batch_size = 20)

vgg=VGG16(include_top = False, input_shape=(224,224,3))

for layer in vgg.layers:
  print(layer)

len(vgg.layers)

for layer in vgg.layers:
  layer.trainable=False

x=Flatten()(vgg.output)

output=Dense(28,activation='softmax')(x)

vgg16= Model(vgg.input,output)

vgg16.summary()

opt = Adam(learning_rate=0.0001)

early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)

vgg16.compile(optimizer='adam' , loss='categorical_crossentropy',metrics=['accuracy'])

history =vgg16.fit(train, validation_data=test, epochs=15, steps_per_epoch=20, callbacks=[early_stopping])

class_labels = train.class_indices
print(class_labels)
labels=dict((v,k) for k,v in class_labels.items())
print(labels)

img_path = '/content/output_dataset/train/Bellpepper__Healthy/freshPepper (103).jpg'

import numpy as np

img = load_img(img_path, target_size=(224, 224))
x = img_to_array(img)
x = preprocess_input(x)
preds = vgg16.predict(np.array([x]))

print(preds)

img_path = '/content/output_dataset/train/Mango__Rotten/144.jpg'

import numpy as np

img = load_img(img_path, target_size=(224, 224))
x = img_to_array(img)
x = preprocess_input(x)
preds = vgg16.predict(np.array([x]))
display(img)
print("Image is tested successfully. \n Image belongs to ",labels[np.argmax(preds)],"class.")
confidence = round(float(np.max(preds)) * 100, 2)
print(confidence)

# Pick random image
folder = '/content/output_dataset/val/Banana__Rotten'
img_name = random.choice(os.listdir(folder))
img_path = os.path.join(folder, img_name)

# Predict
img = load_img(img_path, target_size=(224, 224))
x = preprocess_input(img_to_array(img))
preds = vgg16.predict(np.array([x]))
predicted_class = labels[np.argmax(pred)]

# Display image and result
display(img)
print("Predicted:", predicted_class)
confidence = round(float(np.max(preds)) * 100, 2)
print(confidence)

from google.colab import files
vgg16.save("vgg16_detector.h5")
files.download("vgg16_detector.h5")

img_path ='/content/apple_rotten1.jpeg'

import numpy as np

img = load_img(img_path, target_size=(224, 224))
x = img_to_array(img)
x = preprocess_input(x)
preds = vgg16.predict(np.array([x]))
print(preds)
display(img)
print("Image is tested successfully. \n Image belongs to ",labels[np.argmax(preds)],"class.")
confidence = round(float(np.max(preds)) * 100, 2)
print(confidence)

